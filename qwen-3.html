<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qwen 3 Details - Top Open Source LLM | ainfo.dev</title>
    <meta name="description" content="Deep dive into Qwen 3: Alibaba's 235B MoE flagship with hybrid thinking modes and 119 language support.">
    <meta property="og:title" content="Qwen 3 Details - Top Open Source LLM">
    <meta property="og:description" content="Deep dive into Qwen 3: Alibaba's 235B MoE flagship with hybrid thinking modes.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://ainfo.dev/qwen-3.html">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=Fira+Code:wght@400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="background-gradient"></div>
    
    <header>
        <nav class="container">
            <a href="index.html" class="logo">ainfo.dev</a>
        </nav>
    </header>

    <main class="container detail-page">
        <a href="index.html" class="back-link">‚Üê Back to Top 10</a>
        
        <section class="hero-detail">
            <span class="badge qwen">Alibaba Cloud</span>
            <h1>Qwen 3</h1>
            <p class="subtitle">The multilingual reasoning powerhouse with hybrid thinking modes and 1M+ token context.</p>
        </section>

        <div class="content-grid">
            <section class="info-card">
                <h2>Generic Info</h2>
                <ul class="specs-list">
                    <li><strong>Publisher:</strong> Alibaba Cloud</li>
                    <li><strong>Release Date:</strong> April 2025</li>
                    <li><strong>Parameters:</strong> 235B Total (22B Active) - Flagship; 0.6B to 235B range</li>
                    <li><strong>Context Window:</strong> 128K tokens (extendable to 1M+)</li>
                    <li><strong>License:</strong> Apache 2.0</li>
                    <li><strong>Key Capabilities:</strong> Hybrid Thinking Modes, 119 Languages, Coding, Math, Agent Tools</li>
                </ul>
                <p class="summary">
                    Qwen 3 introduces revolutionary hybrid reasoning with "thinking" mode for complex multi-step problems and "non-thinking" mode for fast general responses. The MoE architecture (128 experts, 8 active) delivers frontier performance at a fraction of the compute cost. Support for 119 languages makes it the most multilingual open model available.
                </p>
            </section>

            <section class="info-card">
                <h2>Hello World Guide</h2>
                <p>Run Qwen 3 locally using Hugging Face <code>transformers</code>.</p>
                <div class="code-block">
                    <div class="code-header">Python</div>
                    <pre><code class="language-python">from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-32B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "Solve this step by step: What is 15% of 340?"
messages = [
    {"role": "system", "content": "You are a helpful assistant. Think carefully before answering."},
    {"role": "user", "content": prompt}
]

text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    enable_thinking=True  # Enable thinking mode for complex tasks
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
</code></pre>
                </div>
            </section>

            <section class="info-card">
                <h2>Industry Usage</h2>
                <div class="usage-grid">
                    <div class="usage-item">
                        <h3>Complex Problem Solving</h3>
                        <p>Thinking mode excels at multi-step math, scientific reasoning, and strategic planning tasks.</p>
                    </div>
                    <div class="usage-item">
                        <h3>Global Applications</h3>
                        <p>119 language support enables true global deployment for customer service and content generation.</p>
                    </div>
                    <div class="usage-item">
                        <h3>Agentic Workflows</h3>
                        <p>Native tool integration and function calling powers sophisticated AI agents and automation.</p>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; <span id="year">2026</span> ainfo.dev. All rights reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
